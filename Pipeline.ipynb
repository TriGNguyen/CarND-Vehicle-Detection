{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mkdir data\n",
    "# cd data\n",
    "# wget https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles.zip\n",
    "# unzip vehicles.zip\n",
    "# wget https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles.zip\n",
    "# unzip non-vehicles.zip\n",
    "# https://github.com/udacity/self-driving-car/tree/master/annotations\n",
    "# wget http://bit.ly/udacity-annotations-autti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "from glob import glob\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "from time import time\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(threshold=10)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PREFIX_PATH = '/Users/tringuyen/OneDrive/Documents/2017 - Udacity Self Driving Car course/CarND-Vehicle-Detection/'\n",
    "# PREFIX_PATH = '/var/storage/shared/ipgsrch/trnguye/Google-Neural-Machine-Translation-GNMT-/tmp/CarND-Vehicle-Detection/'\n",
    "\n",
    "PATH_TO_GTI_FAR_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/vehicles/GTI_Far/*.png'\n",
    "PATH_TO_GTI_LEFT_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/vehicles/GTI_Left/*.png'\n",
    "PATH_TO_GTI_CLOSE_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/vehicles/GTI_MiddleClose/*.png'\n",
    "PATH_TO_GTI_RIGHT_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/vehicles/GTI_Right/*.png'\n",
    "PATH_TO_KITTI_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/vehicles/KITTI*/*.png'\n",
    "PATH_TO_GTI_NON_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/non-vehicles/GTI/*.png'\n",
    "PATH_TO_KITTI_NON_VEHICLES = \\\n",
    "    PREFIX_PATH + 'data/non-vehicles/Extras/*.png'\n",
    "    \n",
    "PATH_TO_TEST_IMAGES = PREFIX_PATH + 'test_images/*.jpg'\n",
    "\n",
    "PATH_TO_TEST_VIDEO_INTPUT = PREFIX_PATH + 'test_video.mp4'\n",
    "PATH_TO_TEST_VIDEO_OUTPUT = PREFIX_PATH + 'test_video_out.mp4'\n",
    "\n",
    "PATH_TO_PROJECT_VIDEO_INTPUT = PREFIX_PATH + 'project_video.mp4'\n",
    "PATH_TO_PROJECT_VIDEO_OUTPUT = PREFIX_PATH + 'project_video_out.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 4\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MANUAL_SPLIT_VEHICLE_FILE_PATHS = [PATH_TO_GTI_FAR_VEHICLES, \n",
    "                                   PATH_TO_GTI_LEFT_VEHICLES, \n",
    "                                   PATH_TO_GTI_CLOSE_VEHICLES, \n",
    "                                   PATH_TO_GTI_RIGHT_VEHICLES]\n",
    "RANDOM_SPLIT_VEHICLE_FILE_PATHS = [PATH_TO_KITTI_VEHICLES]\n",
    "MANUAL_SPLIT_NON_VEHICLE_FILE_PATHS = [PATH_TO_GTI_NON_VEHICLES]\n",
    "RANDOM_SPLIT_NON_VEHICLE_FILE_PATHS = [PATH_TO_KITTI_NON_VEHICLES]\n",
    "TRAIN_DEV_TEST_SPLIT = (0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data(p_manual_split_file_paths, p_random_split_file_paths):\n",
    "    output_train = []\n",
    "    output_dev = []\n",
    "    output_test = []\n",
    "\n",
    "    if p_manual_split_file_paths is not None:\n",
    "        for paths_to_file in p_manual_split_file_paths:\n",
    "            paths_to_file = glob(paths_to_file)\n",
    "            nb_files = len(paths_to_file)\n",
    "            train, dev, test = \\\n",
    "                np.split(paths_to_file, \n",
    "                         [int(nb_files * TRAIN_DEV_TEST_SPLIT[0]), \n",
    "                          int(nb_files * (TRAIN_DEV_TEST_SPLIT[0] + TRAIN_DEV_TEST_SPLIT[1]))])\n",
    "            output_train.append(train)\n",
    "            output_dev.append(dev)\n",
    "            output_test.append(test)\n",
    "                \n",
    "    for paths_to_file in p_random_split_file_paths:\n",
    "        paths_to_file = glob(paths_to_file)\n",
    "        train, dev_test = train_test_split(paths_to_file, train_size=TRAIN_DEV_TEST_SPLIT[0])\n",
    "        dev, test = \\\n",
    "            train_test_split(\n",
    "                dev_test,\n",
    "                train_size=TRAIN_DEV_TEST_SPLIT[1] / (TRAIN_DEV_TEST_SPLIT[1] + TRAIN_DEV_TEST_SPLIT[2]))\n",
    "        output_train.append(train)\n",
    "        output_dev.append(dev)\n",
    "        output_test.append(test)\n",
    "\n",
    "    return np.concatenate(output_train), np.concatenate(output_dev), np.concatenate(output_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shuffle_image_paths(p_vehicle_image_file_paths, p_non_vehicle_image_file_paths):\n",
    "    image_paths = np.concatenate((p_vehicle_image_file_paths, p_non_vehicle_image_file_paths))\n",
    "    labels = np.concatenate((np.ones(len(p_vehicle_image_file_paths)), \n",
    "                             np.zeros(len(p_non_vehicle_image_file_paths))))\n",
    "    image_paths, labels = shuffle(image_paths, labels)\n",
    "    \n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_features_from_single_image(\n",
    "        p_image_file_path, \n",
    "        p_color_space='YCrCb', \n",
    "        p_resize=(64, 64),\n",
    "        p_color_histogram_bin=32,\n",
    "        p_color_histogram_bin_range=(0, 256),\n",
    "        p_hog_orient=9, \n",
    "        p_hog_pix_per_cell=8, \n",
    "        p_hog_cell_per_block=2,\n",
    "        p_feature_types=['bin spacial', 'histogram', 'hog']):\n",
    "\n",
    "    image = cv2.imread(p_image_file_path)\n",
    "\n",
    "    if p_color_space == 'HSV':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif p_color_space == 'LUV':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif p_color_space == 'HLS':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    elif p_color_space == 'YUV':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    elif p_color_space == 'YCrCb':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)     \n",
    "\n",
    "    image = cv2.resize(image, p_resize)\n",
    "        \n",
    "    features = np.array([])\n",
    "    if 'bin spacial' in p_feature_types:\n",
    "        bin_spatial_features = image.ravel()\n",
    "        features = np.concatenate((features, bin_spatial_features))\n",
    "    \n",
    "    if 'histogram' in p_feature_types:\n",
    "        color_histograms = []\n",
    "        for channel in range(image.shape[2]):\n",
    "            color_histograms.append(np.histogram(image[:, :, channel], \n",
    "                                                 bins=p_color_histogram_bin, \n",
    "                                                 range=p_color_histogram_bin_range)[0])\n",
    "        features = np.concatenate((features, np.ravel(color_histograms)))\n",
    "\n",
    "    if 'hog' in p_feature_types:\n",
    "        hog_features = []\n",
    "        for channel in range(image.shape[2]):\n",
    "            hog_features.append(\n",
    "                hog(image[:, :, channel],\n",
    "                    orientations=p_hog_orient,\n",
    "                    pixels_per_cell=(p_hog_pix_per_cell, p_hog_pix_per_cell),\n",
    "                    cells_per_block=(p_hog_cell_per_block, p_hog_cell_per_block),\n",
    "                    transform_sqrt=True,\n",
    "                    visualise=False))\n",
    "        features = np.concatenate((features, np.ravel(hog_features)))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_features_from_file_paths(p_image_file_paths):\n",
    "    features = []\n",
    "    \n",
    "    for image_file_path in p_image_file_paths:\n",
    "        features.append(extract_features_from_single_image(image_file_path))\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(p_verbal=True):            \n",
    "    train_vehicles_file_paths, dev_vehicles_file_paths, test_vehicles_file_paths = \\\n",
    "        load_data(p_manual_split_file_paths=MANUAL_SPLIT_VEHICLE_FILE_PATHS, \n",
    "                  p_random_split_file_paths=RANDOM_SPLIT_VEHICLE_FILE_PATHS)\n",
    "    train_non_vehicles_file_paths, dev_non_vehicles_file_paths, test_non_vehicles_file_paths = \\\n",
    "        load_data(p_manual_split_file_paths=MANUAL_SPLIT_NON_VEHICLE_FILE_PATHS, \n",
    "                  p_random_split_file_paths=RANDOM_SPLIT_NON_VEHICLE_FILE_PATHS)\n",
    "        \n",
    "    train_image_file_paths, train_labels = \\\n",
    "        shuffle_image_paths(train_vehicles_file_paths, train_non_vehicles_file_paths)\n",
    "    dev_image_file_paths, dev_labels = \\\n",
    "        shuffle_image_paths(dev_vehicles_file_paths, dev_non_vehicles_file_paths)\n",
    "    test_image_file_paths, test_labels = \\\n",
    "        shuffle_image_paths(test_vehicles_file_paths, test_non_vehicles_file_paths)\n",
    "    \n",
    "    if p_verbal:\n",
    "        start_time = time()\n",
    "    train_features = extract_features_from_file_paths(train_image_file_paths)\n",
    "    dev_features = extract_features_from_file_paths(dev_image_file_paths)\n",
    "    test_features = extract_features_from_file_paths(test_image_file_paths)\n",
    "    \n",
    "    all_features = np.concatenate((train_features, dev_features, test_features)).astype(np.float64)                        \n",
    "    feature_scaler = StandardScaler().fit(all_features)\n",
    "    train_scaled_features = feature_scaler.transform(train_features)\n",
    "    dev_scaled_features = feature_scaler.transform(dev_features)\n",
    "    test_scaled_features = feature_scaler.transform(test_features)\n",
    "    if p_verbal:\n",
    "        print('Extract features in %d seconds' % (time() - start_time))\n",
    "    \n",
    "    if p_verbal:\n",
    "        start_time = time()\n",
    "    # classifier = SVC()\n",
    "    classifier = LinearSVC()\n",
    "    # n_estimators = 10\n",
    "    # classifier = BaggingClassifier(SVC(), max_samples=1.0 / n_estimators, n_estimators=n_estimators))\n",
    "\n",
    "    # classifier = RandomForestClassifier(min_samples_leaf=20)\n",
    "    classifier.fit(train_scaled_features, train_labels)\n",
    "    if p_verbal:\n",
    "        print('Train classifier in %d seconds' % (time() - start_time))\n",
    "\n",
    "    if p_verbal:\n",
    "        start_time = time()\n",
    "        train_accuracy = classifier.score(train_scaled_features, train_labels)\n",
    "        print()\n",
    "        print('Train accuracy: %f' % train_accuracy)\n",
    "        print('Evaluate train accuracy in %d seconds' % (time() - start_time))\n",
    "\n",
    "        start_time = time()\n",
    "        dev_accuracy = classifier.score(dev_scaled_features, dev_labels)\n",
    "        print()\n",
    "        print('Dev accuracy: %f' % dev_accuracy)\n",
    "        print('Evaluate dev accuracy in %d seconds' % (time() - start_time))\n",
    "\n",
    "        start_time = time()\n",
    "        test_accuracy = classifier.score(test_scaled_features, test_labels)\n",
    "        print()\n",
    "        print('Test accuracy: %f' % test_accuracy)\n",
    "        print('Evaluate test accuracy in %d seconds' % (time() - start_time))\n",
    "        \n",
    "        print()\n",
    "        print('Sample predictions:')\n",
    "        for i in range(10):\n",
    "            random_num = random.randint(1, 10)\n",
    "            image_file_path = test_image_file_paths[random_num]\n",
    "            features = test_scaled_features[random_num].reshape(1, -1)\n",
    "            label = test_labels[random_num]\n",
    "            plt.figure()\n",
    "            plt.imshow(cv2.imread(image_file_path)[:,:,::-1])\n",
    "            plt.title('Label: %d ; Predict: %d' % (label, classifier.predict(features)))      \n",
    "    \n",
    "    return feature_scaler, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_scaler, classifier = train_classifier(p_verbal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_single_heat_map(\n",
    "        p_image, \n",
    "        p_row_span,\n",
    "        p_feature_scaler,\n",
    "        p_classifier,\n",
    "        p_image_window_size=(64, 64),\n",
    "        p_classifier_color_space='YCrCb',\n",
    "        p_classifier_resize=(64, 64),\n",
    "        p_classifier_color_histogram_bin=32,\n",
    "        p_classifier_color_histogram_bin_range=(0, 256),\n",
    "        p_classifier_hog_orient=9, \n",
    "        p_classifier_hog_pix_per_cell=8, \n",
    "        p_classifier_hog_cell_per_block=2,\n",
    "        p_classifier_feature_types=['bin spacial', 'histogram', 'hog']):\n",
    "    \n",
    "    heatmap = np.zeros((p_image.shape[0], p_image.shape[1]))\n",
    "\n",
    "    search_area = p_image[p_row_span[0] : p_row_span[1], :, :]\n",
    "    \n",
    "    if p_classifier_color_space == 'HSV':\n",
    "        search_area = cv2.cvtColor(search_area, cv2.COLOR_BGR2HSV)\n",
    "    elif p_classifier_color_space == 'LUV':\n",
    "        search_area = cv2.cvtColor(search_area, cv2.COLOR_BGR2LUV)\n",
    "    elif p_classifier_color_space == 'HLS':\n",
    "        search_area = cv2.cvtColor(search_area, cv2.COLOR_BGR2HLS)\n",
    "    elif p_classifier_color_space == 'YUV':\n",
    "        search_area = cv2.cvtColor(search_area, cv2.COLOR_BGR2YUV)\n",
    "    elif p_classifier_color_space == 'YCrCb':\n",
    "        search_area = cv2.cvtColor(search_area, cv2.COLOR_BGR2YCrCb) \n",
    "        \n",
    "    row_scaler = p_image_window_size[0] / p_classifier_resize[0] \n",
    "    col_scaler = p_image_window_size[1] / p_classifier_resize[1]\n",
    "    search_area = cv2.resize(search_area, \n",
    "                             (np.int(search_area.shape[1] / col_scaler), \n",
    "                              np.int(search_area.shape[0] / row_scaler)))\n",
    "\n",
    "    n_row_blocks = (search_area.shape[0] // p_classifier_hog_pix_per_cell) - p_classifier_hog_cell_per_block + 1\n",
    "    n_col_blocks = (search_area.shape[1] // p_classifier_hog_pix_per_cell) - p_classifier_hog_cell_per_block + 1\n",
    "\n",
    "    n_row_blocks_per_window = \\\n",
    "        (p_classifier_resize[0] // p_classifier_hog_pix_per_cell) - p_classifier_hog_cell_per_block + 1\n",
    "    n_col_blocks_per_window = \\\n",
    "        (p_classifier_resize[1] // p_classifier_hog_pix_per_cell) - p_classifier_hog_cell_per_block + 1\n",
    "\n",
    "    cells_per_step = p_classifier_hog_cell_per_block // 2\n",
    "\n",
    "    n_row_block_steps = (n_row_blocks - n_row_blocks_per_window) // cells_per_step\n",
    "    n_col_block_steps = (n_col_blocks - n_col_blocks_per_window) // cells_per_step\n",
    "\n",
    "    hog_image_features = []\n",
    "    for channel in range(search_area.shape[2]):\n",
    "        hog_image_features.append(\n",
    "            hog(search_area[:, :, channel],\n",
    "                orientations=p_classifier_hog_orient,\n",
    "                pixels_per_cell=(p_classifier_hog_pix_per_cell, p_classifier_hog_pix_per_cell),\n",
    "                cells_per_block=(p_classifier_hog_cell_per_block, p_classifier_hog_cell_per_block),\n",
    "                transform_sqrt=True,\n",
    "                visualise=False,\n",
    "                feature_vector=False))\n",
    "\n",
    "    for row_block_step in range(n_row_block_steps):\n",
    "        for col_block_step in range(n_col_block_steps):\n",
    "\n",
    "            row_block = row_block_step * cells_per_step\n",
    "            col_block = col_block_step * cells_per_step\n",
    "\n",
    "            hog_window_features = []\n",
    "            for channel in range(search_area.shape[2]):\n",
    "                hog_window_features.append(\n",
    "                    hog_image_features[channel][\n",
    "                        row_block : row_block + n_row_blocks_per_window, \n",
    "                        col_block : col_block + n_col_blocks_per_window])\n",
    "                       \n",
    "            hog_window_features = np.ravel(hog_window_features)\n",
    "\n",
    "            row_top = row_block * p_classifier_hog_pix_per_cell\n",
    "            col_left = col_block * p_classifier_hog_pix_per_cell\n",
    "\n",
    "            window_image = search_area[row_top : row_top + p_classifier_resize[0], \n",
    "                                       col_left : col_left + p_classifier_resize[1]]\n",
    "          \n",
    "            bin_spatial_features = window_image.ravel()\n",
    "                       \n",
    "            color_histograms = []\n",
    "            for channel in range(window_image.shape[2]):\n",
    "                color_histograms.append(np.histogram(window_image[:, :, channel], \n",
    "                                                     bins=p_classifier_color_histogram_bin, \n",
    "                                                     range=p_classifier_color_histogram_bin_range)[0])\n",
    "            color_histograms = np.ravel(color_histograms)\n",
    "\n",
    "            features = np.concatenate((bin_spatial_features, color_histograms, hog_window_features))\n",
    "            features = features.reshape(1, -1)\n",
    "            features = p_feature_scaler.transform(features)\n",
    "                       \n",
    "            prediction = p_classifier.predict(features)\n",
    "            if prediction == 1:\n",
    "                heatmap[p_row_span[0] + int(row_top * row_scaler) : \n",
    "                            p_row_span[0] + int((row_top + p_classifier_resize[0]) * row_scaler), \n",
    "                        int(col_left * col_scaler) : \n",
    "                            int((col_left + p_classifier_resize[1]) * col_scaler)] += 1\n",
    "            \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_aggregated_heat_map(\n",
    "        p_image,\n",
    "        p_row_span,\n",
    "        p_feature_scaler,\n",
    "        p_classifier,\n",
    "        p_image_window_sizes=IMAGE_WINDOW_SIZES,\n",
    "        p_verbose=True):\n",
    "    \n",
    "    heatmaps = []\n",
    "    \n",
    "    for image_window_size in p_image_window_sizes:\n",
    "        heatmaps.append(create_single_heat_map(\n",
    "            p_image=p_image,\n",
    "            p_row_span=p_row_span,\n",
    "            p_feature_scaler=p_feature_scaler,\n",
    "            p_classifier=p_classifier,\n",
    "            p_image_window_size=image_window_size))\n",
    "    \n",
    "    heatmaps = np.sum(heatmaps, axis=0)\n",
    "\n",
    "    if p_verbose:\n",
    "        plt.figure()\n",
    "        plt.imshow(test_image[:,:,::-1])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(heatmaps, cmap='hot', interpolation='nearest')\n",
    "    \n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(p_image, p_heatmap, p_threshold=HEATMAP_THRESHOLD, p_verbose=True):\n",
    "    threshold, thresholded_image = cv2.threshold(\n",
    "        p_heatmap.astype(np.uint8), thresh=p_threshold, maxval=1, type=cv2.THRESH_BINARY)\n",
    "    \n",
    "    im3, contours, hierarchy = cv2.findContours(thresholded_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i in range(0, len(contours)):\n",
    "       contour = contours[i]\n",
    "       x, y, w, h = cv2.boundingRect(contour)\n",
    "       cv2.rectangle(p_image, (x, y), (x + w, y + h), (0, 0, 255), 10)\n",
    "    \n",
    "    if p_verbose:\n",
    "        plt.figure()\n",
    "        plt.imshow(p_image[:, :, : : -1])\n",
    "    \n",
    "    return p_image, thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npath_to_test_images = glob(PATH_TO_TEST_IMAGES)\\n\\ntest_image = cv2.imread(path_to_test_images[4])\\n\\nheatmap = create_aggregated_heat_map(\\n    p_image=test_image,\\n    p_row_span=(400, 656),\\n    p_feature_scaler=feature_scaler,\\n    p_classifier=classifier)\\n\\ndraw_boxes(test_image, heatmap)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "path_to_test_images = glob(PATH_TO_TEST_IMAGES)\n",
    "\n",
    "test_image = cv2.imread(path_to_test_images[4])\n",
    "\n",
    "heatmap = create_aggregated_heat_map(\n",
    "    p_image=test_image,\n",
    "    p_row_span=(400, 656),\n",
    "    p_feature_scaler=feature_scaler,\n",
    "    p_classifier=classifier)\n",
    "\n",
    "draw_boxes(test_image, heatmap)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_video(\n",
    "        p_path_to_input_video, \n",
    "        p_path_to_output_video,\n",
    "        p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "        p_image_window_sizes=IMAGE_WINDOW_SIZES,\n",
    "        p_sample=5):\n",
    "\n",
    "    input_video = cv2.VideoCapture(p_path_to_input_video)\n",
    "    output_video = None\n",
    "\n",
    "    frame_num = -1\n",
    "    while True:\n",
    "        ret, frame = input_video.read()\n",
    "        frame_num += 1\n",
    "        if p_sample > 0 and (frame_num % p_sample) != 0:\n",
    "            continue\n",
    "            \n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        if output_video is None:\n",
    "            output_video = cv2.VideoWriter(\n",
    "                p_path_to_output_video, \n",
    "                cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                30, \n",
    "                (frame.shape[1], int(frame.shape[0] * 1.5)))\n",
    "\n",
    "        heatmap = create_aggregated_heat_map(\n",
    "            p_image=frame,\n",
    "            p_row_span=(400, 656),\n",
    "            p_feature_scaler=feature_scaler,\n",
    "            p_classifier=classifier,\n",
    "            p_image_window_sizes=p_image_window_sizes,\n",
    "            p_verbose=False)\n",
    "\n",
    "        lower_output_frame, thresholded_frame = draw_boxes(frame, heatmap, p_threshold=p_hitmap_threshold, p_verbose=False)\n",
    "        \n",
    "        #heatmap = ny.ndarray(plt.imshow(heatmap, cmap='hot'))\n",
    "        heatmap = heatmap / heatmap.max()\n",
    "        cmap = plt.get_cmap('hot')\n",
    "        rgba_img = cmap(heatmap)\n",
    "        rgb_img = np.delete(rgba_img, 3, 2)\n",
    "        heatmap = cv2.resize(rgb_img[:, :, ::-1], (heatmap.shape[1] // 2, heatmap.shape[0] // 2))\n",
    "        heatmap = heatmap * 255\n",
    "\n",
    "        thresholded_frame = cv2.resize(\n",
    "            thresholded_frame, (thresholded_frame.shape[1] // 2, thresholded_frame.shape[0] // 2)) * 255\n",
    "        thresholded_frame = cv2.cvtColor(thresholded_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        upper_output_frame = np.concatenate((heatmap, thresholded_frame), axis=1)\n",
    "        \n",
    "        output_frame = np.concatenate(\n",
    "            (upper_output_frame, lower_output_frame),\n",
    "            axis=0)\n",
    "\n",
    "        cv2.putText(output_frame, \n",
    "                    'Frame %d' % frame_num,\n",
    "                    (50, 450),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,\n",
    "                    (0, 0, 255),\n",
    "                    5)\n",
    "        \n",
    "        output_frame = output_frame.astype(np.uint8)\n",
    "\n",
    "        output_video.write(output_frame)\n",
    "        \n",
    "        print('.', end='')\n",
    "\n",
    "    input_video.release()\n",
    "    output_video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................"
     ]
    }
   ],
   "source": [
    "HEATMAP_THRESHOLD = 4\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_TEST_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PATH_TO_TEST_VIDEO_OUTPUT,\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-128df6ef5979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mp_path_to_output_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREFIX_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test_video_out_01.mp4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mp_hitmap_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEATMAP_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     p_image_window_sizes=IMAGE_WINDOW_SIZES)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-7a58a91ee73a>\u001b[0m in \u001b[0;36mprocess_video\u001b[0;34m(p_path_to_input_video, p_path_to_output_video, p_hitmap_threshold, p_image_window_sizes)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mp_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mp_image_window_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_image_window_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             p_verbose=False)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlower_output_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholded_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_hitmap_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-56fb7fa85b3b>\u001b[0m in \u001b[0;36mcreate_aggregated_heat_map\u001b[0;34m(p_image, p_row_span, p_feature_scaler, p_classifier, p_image_window_sizes, p_verbose)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mp_feature_scaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_feature_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mp_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             p_image_window_size=image_window_size))\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mheatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-6ce577d887ba>\u001b[0m in \u001b[0;36mcreate_single_heat_map\u001b[0;34m(p_image, p_row_span, p_feature_scaler, p_classifier, p_image_window_size, p_classifier_color_space, p_classifier_resize, p_classifier_color_histogram_bin, p_classifier_color_histogram_bin_range, p_classifier_hog_orient, p_classifier_hog_pix_per_cell, p_classifier_hog_cell_per_block, p_classifier_feature_types)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_spatial_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_histograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhog_window_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_feature_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tringuyen/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    644\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy,\n\u001b[1;32m    645\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tringuyen/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tringuyen/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# false positives from overflow in sum method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n\u001b[0m\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n",
      "\u001b[0;32m/Users/tringuyen/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "HEATMAP_THRESHOLD = 4\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_01.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 6\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_02.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 8\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_03.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 18\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_04.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 4\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_05.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 6\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_06.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 8\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_07.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 10\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_08.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 4\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64), (32, 32)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_09.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 6\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64), (32, 32)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_10.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 8\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64), (32, 32)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_11.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tringuyen/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:39: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/tringuyen/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/colors.py:494: RuntimeWarning: invalid value encountered in less\n",
      "  cbook._putmask(xa, xa < 0.0, -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................."
     ]
    }
   ],
   "source": [
    "HEATMAP_THRESHOLD = 10\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 96), (64, 64), (32, 32)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_12.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 14\n",
    "IMAGE_WINDOW_SIZES = [(128, 128), (96, 192), (96, 96), (64, 128), (64, 64), (32, 64), (32, 32)]\n",
    "\n",
    "process_video(\n",
    "    p_path_to_input_video=PATH_TO_PROJECT_VIDEO_INTPUT, \n",
    "    p_path_to_output_video=PREFIX_PATH + 'test_video_out_14.mp4',\n",
    "    p_hitmap_threshold=HEATMAP_THRESHOLD,\n",
    "    p_image_window_sizes=IMAGE_WINDOW_SIZES)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
